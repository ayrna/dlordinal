{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dlordinal.datasets import FGNet\n",
    "from dlordinal.losses import ExponentialRegularisedCrossEntropyLoss\n",
    "from sklearn.utils import class_weight\n",
    "from torch import cuda, nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from dlordinal.estimator import PytorchEstimator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess of FGNet dataset\n",
    "\n",
    "First, we present the configuration parameters for the experimentation and the number of workers for the *DataLoader*, which defines the number of subprocesses to use for data loading. In this specific case, it refers to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser_params = {\n",
    "    'lr': 1e-3,\n",
    "    'bs': 200,\n",
    "    'epochs': 5,\n",
    "    's': 2,\n",
    "    'c': 0.2,\n",
    "    'beta': 0.5\n",
    "}\n",
    "\n",
    "workers = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the *FGNet* method to download and preprocess the images. Once that is done with the training data, we create a validation partition comprising 15% of the data using the *StratifiedShuffleSplit* method. Finally, with all the partitions, we load the images using a method called *DataLoader*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already processed and verified\n",
      "Files already split and verified\n",
      "Using cuda device\n",
      "Detected image shape: [3, 128, 128]\n",
      "class_weights=array([1.60843373, 0.55394191, 1.02692308, 0.78070175, 1.12184874,\n",
      "       2.34210526])\n"
     ]
    }
   ],
   "source": [
    "fgnet = FGNet(root=\"./datasets/fgnet\", download=True, process_data=True)\n",
    "\n",
    "train_data = ImageFolder(\n",
    "    root=\"./datasets/fgnet/FGNET/train\", transform=Compose([ToTensor()])\n",
    ")\n",
    "test_data = ImageFolder(\n",
    "    root=\"./datasets/fgnet/FGNET/test\", transform=Compose([ToTensor()])\n",
    ")\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "classes = train_data.classes\n",
    "targets = train_data.targets\n",
    "\n",
    "# Get CUDA device\n",
    "device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, batch_size=optimiser_params[\"bs\"], shuffle=True, num_workers=workers\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, batch_size=optimiser_params[\"bs\"], shuffle=False, num_workers=workers\n",
    ")\n",
    "\n",
    "# Get image shape\n",
    "img_shape = None\n",
    "for X, _ in train_dataloader:\n",
    "    img_shape = list(X.shape[1:])\n",
    "    break\n",
    "print(f\"Detected image shape: {img_shape}\")\n",
    "\n",
    "# Define class weights for imbalanced datasets\n",
    "classes_array = np.array([int(c) for c in classes])\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    \"balanced\", classes=classes_array, y=targets\n",
    ")\n",
    "print(f\"{class_weights=}\")\n",
    "class_weights = (\n",
    "    torch.from_numpy(class_weights).float().to(device)\n",
    ")  # Transform to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We are using a pretrained *ResNet* model, which has previously been trained on ImageNet. We are modifying the last fully connected layer to match the number of classes in our dataset.\n",
    "\n",
    "Finally, we define the *Adam* optimiser, which is used to adjust the network's weights and minimize the error of a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = Adam(model.parameters(), lr=optimiser_params['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "This exponential loss function is based on the introduction of the $L_p$, which means that there is an extra tunable parameter that can be adjusted by the learning algorithm. \n",
    "\n",
    "$$\n",
    "f_j(p, q) = e^{-|j - q|^p}, \\ 1 \\leq p \\leq 2\n",
    "$$\n",
    "\n",
    "where $j = \\mathcal{O} (\\mathcal{C}_j)$, $q = \\mathcal{O} (\\mathcal{C}_q)$ and p parameter can be tweaked manually or cross-validated. Hence, the p parameter controls how much a pattern is penalised when it is classified in class $\\mathcal{C}_j$ and its real class is $\\mathcal{C}_q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = ExponentialRegularisedCrossEntropyLoss(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PytorchEstimator(\n",
    "    model=model, loss_fn=loss_fn, optimizer=optimizer, device=device, max_iter=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "estimate = estimator.fit(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting ...\n",
      "tensor([[ 5.4411,  3.4726,  2.1251, -1.0145, -4.4096, -4.9868],\n",
      "        [ 4.4464,  2.7000,  2.1472, -0.9296, -3.9113, -5.2487],\n",
      "        [ 3.9304,  3.6262,  2.4497, -1.3358, -4.2533, -5.5883],\n",
      "        ...,\n",
      "        [-2.6135, -3.0116, -0.4865, -1.0609,  2.2993,  2.4897],\n",
      "        [ 0.5993,  1.9221,  0.4639, -1.1800, -0.9429, -1.8807],\n",
      "        [-2.3832, -1.2392, -0.6678, -0.5411,  1.5725,  0.9038]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(estimator.predict_proba(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting ...\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 2,\n",
      "        2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 2, 3, 3, 1, 2, 2, 1, 0, 1, 4, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 4, 4, 4, 1, 1, 1, 1, 1, 1, 4, 1, 4,\n",
      "        3, 1, 4, 4, 4, 3, 1, 4, 2, 2, 4, 4, 1, 2, 4, 4, 1, 1, 1, 2, 4, 1, 1, 1,\n",
      "        4, 2, 1, 4, 1, 1, 4, 1, 2, 1, 1, 3, 2, 2, 4, 4, 4, 4, 2, 4, 1, 4, 5, 2,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 1, 4, 5, 4,\n",
      "        4, 5, 5, 4, 4, 0, 5, 1, 4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(estimator.predict(test_dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from dlordinal.datasets import FGNet\n",
    "from dlordinal.losses import ExponentialRegularisedCrossEntropyLoss\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.utils import class_weight\n",
    "from torch import cuda, nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from dlordinal.estimator import PytorchEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess of FGNet dataset\n",
    "\n",
    "First, we present the configuration parameters for the experimentation and the number of workers for the *DataLoader*, which defines the number of subprocesses to use for data loading. In this specific case, it refers to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser_params = {\n",
    "    'lr': 1e-3,\n",
    "    'bs': 200,\n",
    "    'epochs': 5,\n",
    "    's': 2,\n",
    "    'c': 0.2,\n",
    "    'beta': 0.5\n",
    "}\n",
    "\n",
    "workers = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the *FGNet* method to download and preprocess the images. Once that is done with the training data, we create a validation partition comprising 15% of the data using the *StratifiedShuffleSplit* method. Finally, with all the partitions, we load the images using a method called *DataLoader*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already processed and verified\n",
      "Files already split and verified\n",
      "Using cuda device\n",
      "Detected image shape: [3, 128, 128]\n",
      "class_weights=array([1.60843373, 0.55394191, 1.02692308, 0.78070175, 1.12184874,\n",
      "       2.34210526])\n"
     ]
    }
   ],
   "source": [
    "fgnet = FGNet(root=\"./datasets/fgnet\", download=True, process_data=True)\n",
    "\n",
    "train_data = ImageFolder(\n",
    "    root=\"./datasets/fgnet/FGNET/train\", transform=Compose([ToTensor()])\n",
    ")\n",
    "test_data = ImageFolder(\n",
    "    root=\"./datasets/fgnet/FGNET/test\", transform=Compose([ToTensor()])\n",
    ")\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "classes = train_data.classes\n",
    "targets = train_data.targets\n",
    "\n",
    "# Get CUDA device\n",
    "device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, batch_size=optimiser_params[\"bs\"], shuffle=True, num_workers=workers\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, batch_size=optimiser_params[\"bs\"], shuffle=False, num_workers=workers\n",
    ")\n",
    "\n",
    "# Get image shape\n",
    "img_shape = None\n",
    "for X, _ in train_dataloader:\n",
    "    img_shape = list(X.shape[1:])\n",
    "    break\n",
    "print(f\"Detected image shape: {img_shape}\")\n",
    "\n",
    "# Define class weights for imbalanced datasets\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    \"balanced\", classes=[int(c) for c in classes], y=targets\n",
    ")\n",
    "print(f\"{class_weights=}\")\n",
    "class_weights = (\n",
    "    torch.from_numpy(class_weights).float().to(device)\n",
    ")  # Transform to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We are using a pretrained *ResNet* model, which has previously been trained on ImageNet. We are modifying the last fully connected layer to match the number of classes in our dataset.\n",
    "\n",
    "Finally, we define the *Adam* optimiser, which is used to adjust the network's weights and minimize the error of a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = Adam(model.parameters(), lr=optimiser_params['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "This exponential loss function is based on the introduction of the $L_p$, which means that there is an extra tunable parameter that can be adjusted by the learning algorithm. \n",
    "\n",
    "$$\n",
    "f_j(p, q) = e^{-|j - q|^p}, \\ 1 \\leq p \\leq 2\n",
    "$$\n",
    "\n",
    "where $j = \\mathcal{O} (\\mathcal{C}_j)$, $q = \\mathcal{O} (\\mathcal{C}_q)$ and p parameter can be tweaked manually or cross-validated. Hence, the p parameter controls how much a pattern is penalised when it is classified in class $\\mathcal{C}_j$ and its real class is $\\mathcal{C}_q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = ExponentialRegularisedCrossEntropyLoss(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PytorchEstimator(\n",
    "    model=model, loss_fn=loss_fn, optimizer=optimizer, device=device, max_iter=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "estimate = estimator.fit(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting ...\n",
      "tensor([[ 5.4411,  3.4726,  2.1251, -1.0145, -4.4096, -4.9868],\n",
      "        [ 4.4464,  2.7000,  2.1472, -0.9296, -3.9113, -5.2487],\n",
      "        [ 3.9304,  3.6262,  2.4497, -1.3358, -4.2533, -5.5883],\n",
      "        ...,\n",
      "        [-2.6135, -3.0116, -0.4865, -1.0609,  2.2993,  2.4897],\n",
      "        [ 0.5993,  1.9221,  0.4639, -1.1800, -0.9429, -1.8807],\n",
      "        [-2.3832, -1.2392, -0.6678, -0.5411,  1.5725,  0.9038]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(estimator.predict_proba(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting ...\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 2,\n",
      "        2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 2, 3, 3, 1, 2, 2, 1, 0, 1, 4, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 4, 4, 4, 1, 1, 1, 1, 1, 1, 4, 1, 4,\n",
      "        3, 1, 4, 4, 4, 3, 1, 4, 2, 2, 4, 4, 1, 2, 4, 4, 1, 1, 1, 2, 4, 1, 1, 1,\n",
      "        4, 2, 1, 4, 1, 1, 4, 1, 2, 1, 1, 3, 2, 2, 4, 4, 4, 4, 2, 4, 1, 4, 5, 2,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 1, 4, 5, 4,\n",
      "        4, 5, 5, 4, 4, 0, 5, 1, 4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(estimator.predict(test_dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "\n",
    "From the *Ordinal Deep Learning* package, we import the methods that will allow us to work with ordinal datasets.\n",
    "\n",
    "We also import methods from libraries such as *pytorch* and *torchvision* that will allow us to process and work with the datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "\n",
    "from dlordinal.datasets import FGNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGNet\n",
    "\n",
    "To utilize the [FGNet dataset](https://yanweifu.github.io/FG_NET_data/), two instances of the dataset will be created: one for the training data and one for the test data. Each instance will include the following fields:\n",
    "\n",
    "* __root__: an attribute that defines the path where the dataset will be downloaded and extracted.\n",
    "* __download__: an attribute that indicates the desire to perform the dataset download.\n",
    "* __train__: an attribute indicating that only the processed input dataset will be returned if its value is set to TRUE.\n",
    "* __target_transform__: an attribute that defines the transformation to be applied to the targets.\n",
    "* __transform__: an attribute that defines the transformation to be applied to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already processed and verified\n",
      "Files already split and verified\n",
      "Files already downloaded and verified\n",
      "Files already processed and verified\n",
      "Files already split and verified\n"
     ]
    }
   ],
   "source": [
    "fgnet_train = FGNet(\n",
    "    root=\"./datasets\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    target_transform=np.array,\n",
    "    transform=Compose([ToTensor()]),\n",
    ")\n",
    "\n",
    "fgnet_test = FGNet(\n",
    "    root=\"./datasets\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    target_transform=np.array,\n",
    "    transform=Compose([ToTensor()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the `FGNet` objects can be used as any other `VisionDataset` from `torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the FGNet train dataset: 801\n",
      "Targets of the FGNet train dataset: [2 0 0 2 2 3 4 1 3 1 3 3 2 1 2 3 3 2 4 1 3 1 3 2 0 0 3 4 1 3 2 4 1 1 4 4 4\n",
      " 1 3 2 2 2 1 0 1 3 3 3 1 1 5 1 2 2 4 0 1 1 1 3 5 1 2 5 0 1 1 1 2 1 3 1 2 1\n",
      " 2 1 2 5 1 3 1 2 3 2 4 1 0 1 1 1 0 2 1 4 3 3 2 1 1 3 0 4 1 0 5 1 3 3 4 1 2\n",
      " 4 5 1 0 4 5 1 0 1 3 4 1 2 5 3 1 3 4 4 4 2 1 3 3 3 2 3 2 1 0 0 1 3 1 3 1 2\n",
      " 5 3 1 4 4 0 2 3 3 2 4 1 3 1 3 2 5 3 1 3 2 1 2 1 1 4 1 1 1 2 3 1 1 4 4 2 3\n",
      " 5 1 4 5 3 5 1 3 0 0 1 3 1 3 1 5 4 1 3 4 1 5 1 0 0 1 3 2 1 4 3 1 1 2 4 1 1\n",
      " 3 1 1 2 1 1 3 3 1 2 4 3 3 0 2 5 4 1 2 1 3 0 1 4 4 2 1 4 3 2 5 3 3 5 3 1 0\n",
      " 4 0 2 3 2 4 1 1 0 4 1 2 2 4 2 0 1 1 0 4 1 1 2 3 4 1 2 4 3 3 1 4 3 5 3 3 2\n",
      " 2 1 4 4 0 2 0 1 5 0 2 0 4 1 3 4 5 0 4 4 3 1 5 1 1 1 3 2 1 2 3 1 4 2 0 3 3\n",
      " 3 4 0 1 1 1 3 2 0 1 1 2 5 1 1 3 2 1 2 0 1 3 3 3 1 1 3 1 1 2 2 1 3 4 3 0 3\n",
      " 4 2 1 1 3 2 4 3 3 4 1 5 1 1 2 1 1 4 1 1 2 3 1 2 2 0 5 1 3 1 3 0 3 4 1 1 2\n",
      " 1 1 1 4 4 0 3 2 1 1 3 1 3 3 2 2 3 3 5 2 4 4 2 4 1 2 1 2 5 1 4 0 2 4 3 0 2\n",
      " 4 4 4 1 1 4 3 1 1 1 1 4 2 3 4 1 3 3 0 1 1 1 2 2 3 4 2 3 3 1 3 5 1 3 2 0 0\n",
      " 0 0 1 5 3 3 1 4 3 5 3 3 1 0 1 4 2 1 2 1 1 2 1 1 1 0 3 4 2 0 3 4 4 1 5 2 5\n",
      " 2 4 4 1 3 4 3 3 1 1 3 1 1 1 1 2 4 1 0 3 0 3 3 2 2 1 0 4 3 1 1 3 1 3 1 1 0\n",
      " 2 0 3 2 4 3 1 4 2 3 5 4 1 5 5 4 5 5 3 4 2 5 5 4 3 0 0 1 2 3 0 0 1 2 4 3 3\n",
      " 5 4 1 4 5 5 2 0 1 1 0 1 2 4 2 4 2 3 4 4 4 1 4 0 1 3 1 2 5 3 1 0 1 2 4 4 3\n",
      " 5 0 0 0 1 1 3 0 5 1 1 1 3 1 2 1 1 3 3 3 2 4 4 1 2 4 5 1 0 1 0 0 1 5 2 1 3\n",
      " 2 1 1 2 3 3 3 3 0 0 1 0 1 0 0 1 0 3 1 1 3 5 2 1 1 2 4 3 3 2 3 4 4 4 3 0 1\n",
      " 4 2 1 5 1 1 2 0 1 0 4 1 2 0 4 1 4 5 1 0 2 1 3 5 0 2 1 4 0 3 2 1 2 1 4 3 2\n",
      " 1 1 2 1 1 1 5 1 1 3 4 1 2 3 3 3 0 1 1 3 4 3 4 2 3 3 1 2 2 4 2 4 1 4 3 3 2\n",
      " 1 3 0 0 3 3 4 1 1 0 5 1 2 3 1 1 3 1 1 5 2 4 5 3]\n",
      "Classes of the FGNet train dataset: [2 0 3 4 1 5]\n",
      "3rd sample of the FGNet train dataset: (tensor([[[0.7294, 0.7294, 0.7294,  ..., 0.8039, 0.8039, 0.8039],\n",
      "         [0.7294, 0.7294, 0.7294,  ..., 0.8039, 0.8039, 0.8039],\n",
      "         [0.7333, 0.7333, 0.7333,  ..., 0.8039, 0.8039, 0.8039],\n",
      "         ...,\n",
      "         [0.6078, 0.6078, 0.6039,  ..., 0.4549, 0.4471, 0.4353],\n",
      "         [0.6039, 0.6039, 0.6039,  ..., 0.4431, 0.4353, 0.4196],\n",
      "         [0.6039, 0.6039, 0.6000,  ..., 0.4314, 0.4235, 0.4196]],\n",
      "\n",
      "        [[0.7490, 0.7490, 0.7490,  ..., 0.8157, 0.8157, 0.8157],\n",
      "         [0.7490, 0.7490, 0.7490,  ..., 0.8157, 0.8157, 0.8157],\n",
      "         [0.7490, 0.7490, 0.7490,  ..., 0.8157, 0.8157, 0.8157],\n",
      "         ...,\n",
      "         [0.6627, 0.6627, 0.6588,  ..., 0.5451, 0.5255, 0.5059],\n",
      "         [0.6588, 0.6588, 0.6588,  ..., 0.5490, 0.5294, 0.5137],\n",
      "         [0.6588, 0.6588, 0.6549,  ..., 0.5451, 0.5294, 0.5255]],\n",
      "\n",
      "        [[0.7647, 0.7647, 0.7608,  ..., 0.7725, 0.7725, 0.7725],\n",
      "         [0.7647, 0.7608, 0.7608,  ..., 0.7725, 0.7725, 0.7725],\n",
      "         [0.7608, 0.7529, 0.7529,  ..., 0.7725, 0.7725, 0.7725],\n",
      "         ...,\n",
      "         [0.6627, 0.6627, 0.6588,  ..., 0.5686, 0.5608, 0.5451],\n",
      "         [0.6588, 0.6588, 0.6588,  ..., 0.5765, 0.5686, 0.5529],\n",
      "         [0.6588, 0.6588, 0.6549,  ..., 0.5765, 0.5725, 0.5686]]]), 2)\n",
      "\n",
      "\n",
      "Number of samples in the FGNet test dataset: 201\n",
      "Targets of the FGNet test dataset: [3 0 2 3 1 3 1 4 5 3 2 3 3 0 1 0 4 1 1 1 1 2 2 1 0 1 1 1 3 5 1 2 1 4 4 4 2\n",
      " 4 3 2 5 0 4 4 4 2 5 2 5 5 1 1 1 3 1 2 5 1 5 0 2 2 1 2 3 1 1 1 4 0 0 3 1 3\n",
      " 4 3 0 2 1 3 5 3 3 3 1 1 1 3 0 1 2 3 3 1 1 4 3 3 2 1 0 4 5 1 1 1 2 3 3 2 3\n",
      " 4 1 4 4 2 5 1 1 0 2 0 2 1 3 3 1 1 1 5 3 1 1 3 4 4 1 4 4 1 2 4 4 3 1 0 1 2\n",
      " 2 3 0 3 2 5 1 4 4 1 2 2 3 3 2 0 4 1 0 2 1 1 2 1 3 3 3 1 0 0 0 1 1 0 5 1 3\n",
      " 4 2 0 3 4 1 3 1 4 3 4 1 2 3 4 2]\n",
      "Classes of the FGNet test dataset: [3 0 2 1 4 5]\n",
      "3rd sample of the FGNet test dataset: (tensor([[[0.7843, 0.7843, 0.7882,  ..., 0.7882, 0.7882, 0.7843],\n",
      "         [0.7843, 0.7843, 0.7882,  ..., 0.7882, 0.7882, 0.7843],\n",
      "         [0.7843, 0.7843, 0.7882,  ..., 0.7882, 0.7843, 0.7843],\n",
      "         ...,\n",
      "         [0.3961, 0.3922, 0.3882,  ..., 0.8196, 0.7451, 0.6863],\n",
      "         [0.3765, 0.3725, 0.3725,  ..., 0.7451, 0.7020, 0.6784],\n",
      "         [0.3765, 0.3725, 0.3725,  ..., 0.6941, 0.6941, 0.6941]],\n",
      "\n",
      "        [[0.7922, 0.7922, 0.7922,  ..., 0.7843, 0.7843, 0.7804],\n",
      "         [0.7922, 0.7922, 0.7922,  ..., 0.7843, 0.7843, 0.7804],\n",
      "         [0.7922, 0.7922, 0.7922,  ..., 0.7843, 0.7804, 0.7804],\n",
      "         ...,\n",
      "         [0.3451, 0.3412, 0.3373,  ..., 0.6078, 0.5176, 0.4510],\n",
      "         [0.3333, 0.3294, 0.3294,  ..., 0.5098, 0.4510, 0.4157],\n",
      "         [0.3333, 0.3294, 0.3294,  ..., 0.4510, 0.4275, 0.4196]],\n",
      "\n",
      "        [[0.7412, 0.7412, 0.7608,  ..., 0.7647, 0.7647, 0.7608],\n",
      "         [0.7412, 0.7412, 0.7608,  ..., 0.7647, 0.7647, 0.7608],\n",
      "         [0.7412, 0.7412, 0.7608,  ..., 0.7647, 0.7608, 0.7608],\n",
      "         ...,\n",
      "         [0.2784, 0.2745, 0.2706,  ..., 0.5608, 0.4745, 0.4118],\n",
      "         [0.2627, 0.2588, 0.2588,  ..., 0.4667, 0.4118, 0.3804],\n",
      "         [0.2627, 0.2588, 0.2588,  ..., 0.4078, 0.3922, 0.3882]]]), 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in the FGNet train dataset: {len(fgnet_train)}\")\n",
    "print(f\"Targets of the FGNet train dataset: {fgnet_train.targets}\")\n",
    "print(f\"Classes of the FGNet train dataset: {fgnet_train.classes}\")\n",
    "print(f\"3rd sample of the FGNet train dataset: {fgnet_train[3]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Number of samples in the FGNet test dataset: {len(fgnet_test)}\")\n",
    "print(f\"Targets of the FGNet test dataset: {fgnet_test.targets}\")\n",
    "print(f\"Classes of the FGNet test dataset: {fgnet_test.classes}\")\n",
    "print(f\"3rd sample of the FGNet test dataset: {fgnet_test[3]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "385611db6ca4af2663855b1744f455946eef985f7b33eb977c97667790417df3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a81d420",
   "metadata": {},
   "source": [
    "# Ordinal Regression with CORN\n",
    "\n",
    "This notebook demonstrates training and evaluation of a Rank-Consistent Ordinal Regression (CORN) model using the Skorch framework with a ResNet-18 backbone, using the FG-NET dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76297f7c",
   "metadata": {},
   "source": [
    "## 1. Setup and imports\n",
    "\n",
    "First, we install the `skorch` library. It is not a dependency of `dlordinal`, but it makes the training and evaluation of the model easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b43ec300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skorch in /home/victor/anaconda3/envs/dlordinal-dev-313/lib/python3.13/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/victor/anaconda3/envs/dlordinal-dev-313/lib/python3.13/site-packages (from skorch) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /home/victor/anaconda3/envs/dlordinal-dev-313/lib/python3.13/site-packages (from skorch) (1.7.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/victor/anaconda3/envs/dlordinal-dev-313/lib/python3.13/site-packages (from skorch) (1.16.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/victor/anaconda3/envs/dlordinal-dev-313/lib/python3.13/site-packages (from skorch) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in /home/victor/anaconda3/envs/dlordinal-dev-313/lib/python3.13/site-packages (from skorch) (4.67.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/victor/anaconda3/envs/dlordinal-dev-313/lib/python3.13/site-packages (from scikit-learn>=0.22.0->skorch) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/victor/anaconda3/envs/dlordinal-dev-313/lib/python3.13/site-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install skorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b5c7a",
   "metadata": {},
   "source": [
    "This cell imports all necessary libraries from PyTorch, Torchvision, Skorch, Scikit-learn, and your custom modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7353b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler\n",
    "\n",
    "# Importing Skorch utilities and callbacks\n",
    "from skorch.dataset import ValidSplit\n",
    "from torch import cuda\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "\n",
    "# Importing custom ordinal components\n",
    "from dlordinal.datasets import FGNet\n",
    "from dlordinal.losses import CORNLoss\n",
    "from dlordinal.metrics import accuracy_off1, amae, mmae, ranked_probability_score\n",
    "from dlordinal.wrappers.corn import CORNClassifierWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15eebb0",
   "metadata": {},
   "source": [
    "## 2. Define Evaluation Metrics Function\n",
    "\n",
    "This utility function processes the output probabilities, calculates various ordinal and classification metrics (including AMMA, QWK, and RPS), and prints the results, including the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf74af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Processes the model output (logits or probabilities) and calculates\n",
    "    a comprehensive set of ordinal and classification metrics.\n",
    "\n",
    "    y_true: True ordinal labels (e.g., [0, 1, 2])\n",
    "    y_pred: Predicted probabilities (for CORN, these are the one-hot results\n",
    "            from the wrapper's predict_proba)\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure y_pred is in probability space for metrics like RPS\n",
    "    if np.allclose(np.sum(y_pred, axis=1), 1):\n",
    "        y_pred_proba = y_pred\n",
    "    else:\n",
    "        # If the input is raw logits, convert to softmax probabilities\n",
    "        y_pred_proba = softmax(y_pred, axis=1)\n",
    "\n",
    "    # Determine the predicted class by finding the index with the max probability\n",
    "    y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # --- Metric Calculation ---\n",
    "    amae_metric = amae(y_true, y_pred_max)\n",
    "    mmae_metric = mmae(y_true, y_pred_max)\n",
    "    mae = mean_absolute_error(y_true, y_pred_max)\n",
    "    acc = accuracy_score(y_true, y_pred_max)\n",
    "    acc_1off = accuracy_off1(y_true, y_pred_max)\n",
    "    qwk = cohen_kappa_score(y_true, y_pred_max, weights=\"quadratic\")\n",
    "    rps = ranked_probability_score(y_true, y_pred_proba)\n",
    "\n",
    "    metrics = {\n",
    "        \"ACC\": acc,\n",
    "        \"1OFF\": acc_1off,\n",
    "        \"MAE\": mae,\n",
    "        \"QWK\": qwk,\n",
    "        \"AMAE\": amae_metric,\n",
    "        \"MMAE\": mmae_metric,\n",
    "        \"RPS\": rps,\n",
    "    }\n",
    "\n",
    "    # --- Output ---\n",
    "    print(\"\\n--- Evaluation Metrics ---\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred_max))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08045df3",
   "metadata": {},
   "source": [
    "## 3. Load Data and Setup Device\n",
    "\n",
    "This cell loads the FG-NET dataset for training and testing and sets up the device, preferring CUDA if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfc0f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already processed and verified\n",
      "Files already split and verified\n",
      "Files already downloaded and verified\n",
      "Files already processed and verified\n",
      "Files already split and verified\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading ---\n",
    "fgnet_train = FGNet(\n",
    "    root=\"./datasets\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=Compose([ToTensor()]),  # Converts images to PyTorch tensors\n",
    ")\n",
    "\n",
    "fgnet_test = FGNet(\n",
    "    root=\"./datasets\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=Compose([ToTensor()]),\n",
    ")\n",
    "\n",
    "num_classes = len(fgnet_train.classes)  # J: Total number of ordinal classes (e.g., 7)\n",
    "classes = fgnet_train.classes\n",
    "targets = fgnet_train.targets\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c34e9",
   "metadata": {},
   "source": [
    "## 4. Model and Skorch Wrapper Definition\n",
    "\n",
    "This cell defines the ResNet-18 model, adapts its final layer for the CORN method (outputting Jâˆ’1 logits), and wraps it with the Skorch and CORN classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c90e668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skorch classifier ready to train with 5 output logits.\n"
     ]
    }
   ],
   "source": [
    "# --- ResNet Adaptation for CORN (J-1 Logits) ---\n",
    "base_model = resnet18(weights=\"IMAGENET1K_V1\")\n",
    "# Replace the final fully connected layer to output J-1 logits\n",
    "base_model.fc = torch.nn.Linear(base_model.fc.in_features, num_classes - 1)\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# --- Skorch NeuralNetClassifier Configuration ---\n",
    "clf = NeuralNetClassifier(\n",
    "    module=base_model,\n",
    "    # Use CORNLoss, passing the total number of classes (J) to the constructor\n",
    "    criterion=CORNLoss(num_classes=num_classes),\n",
    "    optimizer=AdamW,\n",
    "    lr=0.001,\n",
    "    max_epochs=30,\n",
    "    # verbose=0, # Uncomment to suppress Skorch output\n",
    "    train_split=ValidSplit(\n",
    "        0.1, random_state=0\n",
    "    ),  # Use 10% of the training data for internal validation\n",
    "    callbacks=[\n",
    "        # Stop early if validation loss doesn't improve for 5 epochs\n",
    "        EarlyStopping(patience=5, monitor=\"valid_loss\"),\n",
    "        # Reduce LR by 0.5 if validation loss plateaus for 3 epochs\n",
    "        LRScheduler(policy=ReduceLROnPlateau, patience=3, factor=0.5),\n",
    "    ],\n",
    "    device=device,\n",
    "    batch_size=200,\n",
    ")\n",
    "\n",
    "# --- Final CORN Wrapper ---\n",
    "# The CORNClassifierWrapper uses the trained Skorch object (clf)\n",
    "# and provides the Scikit-learn interface, implementing the CORN aggregation logic.\n",
    "corn_clf = CORNClassifierWrapper(clf)\n",
    "\n",
    "print(f\"Skorch classifier ready to train with {num_classes-1} output logits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62032c51",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "This cell executes the training process using the Skorch/CORN wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aea291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training ---\n",
      "  epoch    train_loss    valid_acc    valid_loss      lr      dur\n",
      "-------  ------------  -----------  ------------  ------  -------\n",
      "      1        \u001b[36m0.5372\u001b[0m       \u001b[32m0.0617\u001b[0m        \u001b[35m0.5114\u001b[0m  0.0010  13.2285\n",
      "      2        \u001b[36m0.2260\u001b[0m       \u001b[32m0.0741\u001b[0m        \u001b[35m0.4839\u001b[0m  0.0010  12.5660\n",
      "      3        \u001b[36m0.0920\u001b[0m       0.0494        0.6455  0.0010  12.1744\n",
      "      4        \u001b[36m0.0306\u001b[0m       0.0617        0.6849  0.0010  11.9297\n",
      "      5        \u001b[36m0.0155\u001b[0m       0.0617        \u001b[35m0.3541\u001b[0m  0.0010  13.0846\n",
      "      6        \u001b[36m0.0056\u001b[0m       0.0617        0.3857  0.0010  12.6702\n",
      "      7        \u001b[36m0.0042\u001b[0m       0.0370        0.4297  0.0010  12.3104\n",
      "      8        \u001b[36m0.0019\u001b[0m       0.0370        0.4507  0.0010  12.4775\n",
      "      9        \u001b[36m0.0013\u001b[0m       0.0370        0.4369  0.0010  12.5651\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "--- Training Complete ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting Training ---\")\n",
    "\n",
    "# Skorch automatically handles data loading and iteration.\n",
    "# We pass the FGNet dataset instance and its targets (converted to a LongTensor).\n",
    "corn_clf.fit(X=fgnet_train, y=torch.tensor(fgnet_train.targets, dtype=torch.long))\n",
    "\n",
    "print(\"--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bca441",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Test Set\n",
    "\n",
    "This cell uses the trained classifier to predict probabilities on the test set and calls the metric calculation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7555df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating on Test Set ---\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "ACC: 0.5124\n",
      "1OFF: 0.8756\n",
      "MAE: 0.6517\n",
      "QWK: 0.7337\n",
      "AMAE: 0.7544\n",
      "MMAE: 1.6429\n",
      "RPS: 0.6517\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  6  0  1  0  0]\n",
      " [ 8 37  6  7  2  0]\n",
      " [ 1 12  4 15  0  1]\n",
      " [ 0  3  7 28  4  0]\n",
      " [ 0  0  3  7 17  3]\n",
      " [ 0  1  2  4  5  2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating on Test Set ---\")\n",
    "\n",
    "# Get the raw targets for comparison\n",
    "test_targets = fgnet_test.targets\n",
    "\n",
    "# Get prediction probabilities using the CORN aggregation logic (one-hot output)\n",
    "# This uses the thresholding logic inside the CORNClassifierWrapper\n",
    "test_probs = corn_clf.predict_proba(fgnet_test)\n",
    "\n",
    "# Calculate and display all metrics\n",
    "metrics = calculate_metrics(np.array(test_targets), test_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlordinal-dev-313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
